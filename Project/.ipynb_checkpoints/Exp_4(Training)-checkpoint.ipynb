{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2087a18-5ab0-436a-b4f8-8d020612b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#########################################################################################\n",
    "This is the code for model training of segment size 0.1 seconds but instead of padding \n",
    "we will resample the audio\n",
    "#########################################################################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882f6064-9d35-493e-be6d-56d514fd9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AudioDatasetResample(Dataset):\n",
    "    def __init__(self, lossless_dir, lossy_dir, segment_duration=0.1, target_sample_rate=44000):\n",
    "        \"\"\"\n",
    "        Initializes the dataset and processes songs one by one, ensuring both lossy and lossless\n",
    "        are resampled to 44kHz if needed.\n",
    "        \"\"\"\n",
    "        self.lossless_files = sorted(\n",
    "            [os.path.join(lossless_dir, f) for f in os.listdir(lossless_dir) if os.path.isfile(os.path.join(lossless_dir, f))]\n",
    "        )\n",
    "        self.lossy_files = sorted(\n",
    "            [os.path.join(lossy_dir, f) for f in os.listdir(lossy_dir) if os.path.isfile(os.path.join(lossy_dir, f))]\n",
    "        )\n",
    "\n",
    "        assert len(self.lossless_files) == len(self.lossy_files), \"Mismatch in number of lossless and lossy files!\"\n",
    "\n",
    "        self.segment_duration = segment_duration\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.data = []  # Store valid segment pairs in memory\n",
    "\n",
    "        # Process and add all files\n",
    "        self.process_and_add()\n",
    "\n",
    "    def process_and_add(self):\n",
    "        \"\"\"\n",
    "        Processes each song and adds valid segment pairs to the dataset.\n",
    "        \"\"\"\n",
    "        for idx, (lossless_path, lossy_path) in enumerate(zip(self.lossless_files, self.lossy_files)):\n",
    "            song_data = self.process_pair(lossless_path, lossy_path)\n",
    "            if song_data:\n",
    "                self.data.extend(song_data)\n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(self.lossless_files)} songs...\")\n",
    "\n",
    "        print(f\"Dataset created with {len(self.data)} valid segment pairs.\")\n",
    "\n",
    "    def process_pair(self, lossless_path, lossy_path):\n",
    "        \"\"\"\n",
    "        Processes a pair of lossless and lossy files, resampling if necessary, and splitting into segments.\n",
    "        \"\"\"\n",
    "        lossless_waveform, lossless_sr = torchaudio.load(lossless_path)\n",
    "        lossy_waveform, lossy_sr = torchaudio.load(lossy_path)\n",
    "\n",
    "        # Resample to target sample rate if needed\n",
    "        if lossless_sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=lossless_sr, new_freq=self.target_sample_rate)\n",
    "            lossless_waveform = resampler(lossless_waveform)\n",
    "        if lossy_sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=lossy_sr, new_freq=self.target_sample_rate)\n",
    "            lossy_waveform = resampler(lossy_waveform)\n",
    "\n",
    "        # Segment duration in samples\n",
    "        segment_size = int(self.target_sample_rate * self.segment_duration)\n",
    "\n",
    "        # Split waveforms into segments\n",
    "        lossless_segments = [\n",
    "            lossless_waveform[:, i:i + segment_size]\n",
    "            for i in range(0, lossless_waveform.shape[1], segment_size)\n",
    "            if lossless_waveform[:, i:i + segment_size].shape[1] == segment_size\n",
    "        ]\n",
    "        lossy_segments = [\n",
    "            lossy_waveform[:, i:i + segment_size]\n",
    "            for i in range(0, lossy_waveform.shape[1], segment_size)\n",
    "            if lossy_waveform[:, i:i + segment_size].shape[1] == segment_size\n",
    "        ]\n",
    "\n",
    "        # Ensure equal number of segments\n",
    "        if len(lossless_segments) != len(lossy_segments):\n",
    "            print(f\"Skipping {lossless_path} and {lossy_path} due to unequal segments.\")\n",
    "            return []\n",
    "\n",
    "        return list(zip(lossy_segments, lossless_segments))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single pair of lossy and lossless stereo segments.\n",
    "        \"\"\"\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979c79d-684e-4a82-affe-7c1bf7a7d08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
